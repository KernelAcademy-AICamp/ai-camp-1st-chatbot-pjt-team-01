# 🧪 RAG 기능 테스트 가이드

## 🚀 빠른 시작

### 1. 브라우저 열기
```
http://localhost:5173
```

### 2. 파일 업로드
1. 좌측 메뉴 → **"요약 & Q&A"** 클릭
2. **"새 문서 업로드"** 탭 (기본값)
3. 파일 드래그 앤 드롭 또는 클릭하여 선택
4. **"문서 저장하기"** 버튼 클릭

### 3. RAG 질문하기
1. **"저장된 문서"** 탭 클릭
2. 업로드한 문서 선택 (파일명 표시)
3. 질문 입력
4. **"질문하기"** 버튼 클릭
5. **참고 자료**와 함께 답변 확인!

---

## 📊 RAG 동작 원리

```
파일 업로드
   ↓
텍스트 추출 (PDF/DOCX/TXT)
   ↓
청킹 (5000자 이상 → N개 청크)
   ↓
⭐ 벡터 임베딩 생성 (OpenAI embedding)
   ↓
FAISS 벡터 스토어 저장
   ↓
질문 입력
   ↓
⭐ 유사 문서 검색 (4개 청크)
   ↓
검색된 청크 + 질문 → GPT-3.5
   ↓
답변 생성 (참고 자료 포함)
```

---

## 🧪 테스트 시나리오

### ✅ 시나리오 1: 짧은 문서
**파일**: 3000자 TXT 파일

**예상 결과**:
```
✅ 1개 파일이 성공적으로 처리되었습니다.

1. 짧은문서.txt (12.3 KB)
   - 추출된 텍스트: 3,000자

📊 총 추출 텍스트: 3,000자
💾 저장 ID: upload_20250120_154500_abc123
🗄️ MongoDB 저장 완료
```

**질문**: "이 문서의 주요 내용은?"
**답변**: RAG 기반 답변 + 참고 자료 표시

---

### ✅ 시나리오 2: 긴 문서 (청킹)
**파일**: 15000자 PDF 파일

**예상 결과**:
```
1. 긴문서.pdf (512.5 KB)
   - 추출된 텍스트: 15,000자
   - 청킹: ✅ 3개 청크로 분할됨

📊 총 추출 텍스트: 15,000자
```

**백엔드 로그**:
```
벡터 스토어 생성 완료: upload_20250120_154500_abc123, 35개 청크
```

---

### ✅ 시나리오 3: 여러 파일 동시 업로드
**파일**: PDF 2개 + TXT 1개

**예상 결과**:
```
✅ 3개 파일이 성공적으로 처리되었습니다.

1. 문서1.pdf (256.7 KB)
   - 추출된 텍스트: 8,000자
   - 청킹: ✅ 2개 청크로 분할됨

2. 문서2.pdf (128.3 KB)
   - 추출된 텍스트: 4,500자

3. 메모.txt (5.2 KB)
   - 추출된 텍스트: 1,200자

📊 총 추출 텍스트: 13,700자
```

**RAG**: 3개 파일의 모든 청크를 검색하여 답변

---

### ❌ 시나리오 4: 빈 파일 (에러 처리)
**파일**: 빈 PDF

**예상 결과**:
```
⚠️ 처리 실패한 파일 (1개):

1. 빈파일.pdf
   - 실패 사유: 텍스트 추출 실패 - 파일이 비어있거나 텍스트를 읽을 수 없습니다.
```

---

## 🔍 RAG vs 일반 모드 비교

### RAG 모드 (문서 선택 시)
```
질문: "이 문서에서 AI의 영향은?"

답변: 문서에 따르면, AI는 노동 시장에 큰 변화를 가져올 것으로 예상됩니다...

참고 출처:
- 참고 1: AI 기술의 발전으로 인해 일부 직업은 사라지고...
- 참고 2: 동시에 새로운 직업군이 생겨날 것으로 전망됩니다...
- 참고 3: 특히 반복적인 업무는 자동화될 가능성이 높습니다...
```

### 일반 모드 (문서 선택 안 함)
```
질문: "AI의 영향은?"

답변: (일반적인 GPT 지식 기반 답변)
AI는 다양한 분야에서 영향을 미치고 있습니다...
```

---

## 📁 생성되는 파일

### MongoDB
```
econlux (Database)
└── documents (Collection)
    └── {
          "upload_id": "upload_20250120_154500_abc123",
          "files": [...],
          "total_files": 1,
          ...
        }
```

### 로컬 파일 시스템
```
backend/
├── uploads/
│   └── upload_20250120_154500_abc123_문서.pdf
└── vector_stores/
    └── upload_20250120_154500_abc123.faiss/
        ├── index.faiss
        └── index.pkl
```

---

## 🐛 문제 해결

### "벡터 스토어를 찾을 수 없습니다" 에러
**원인**: 파일 업로드 시 벡터 스토어 생성 실패

**해결**:
1. 백엔드 로그 확인
2. OpenAI API 키 확인
3. 파일 다시 업로드

### "관련 문서를 찾을 수 없습니다" 메시지
**원인**: 질문과 문서 내용이 전혀 관련 없음

**해결**:
1. 질문을 문서 주제와 관련되게 수정
2. 다른 문서 선택

### 답변이 느림
**원인**:
- 긴 문서 → 많은 청크 검색
- OpenAI API 호출

**정상**: RAG는 검색 + LLM 호출로 5-10초 소요

---

## 📊 성능 비교

### 기존 방식 (전체 문서 전달)
- **토큰**: 15,000자 문서 = 약 4,000 토큰
- **비용**: 높음
- **정확도**: 문서가 길면 낮음

### RAG 방식
- **토큰**: 500자 청크 4개 = 약 500 토큰
- **비용**: **약 1/8**
- **정확도**: **높음** (관련 부분만 사용)

---

## ✅ 체크리스트

- [ ] 백엔드 실행 중 (http://localhost:8000)
- [ ] 프론트엔드 실행 중 (http://localhost:5173)
- [ ] MongoDB 연결됨
- [ ] OpenAI API 키 설정됨
- [ ] 파일 업로드 성공
- [ ] "저장된 문서"에 표시됨
- [ ] 문서 선택 가능
- [ ] 질문 시 답변 생성됨
- [ ] 참고 자료 표시됨

---

## 🎯 추천 테스트 파일

1. **짧은 TXT** (1000-3000자)
2. **중간 PDF** (5000-10000자)
3. **긴 문서** (20000자 이상)
4. **빈 파일** (에러 테스트)

---

궁금한 점이나 문제가 발생하면 백엔드 로그를 확인하세요!
